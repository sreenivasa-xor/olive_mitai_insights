{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7a027c05-26ad-4325-b47e-163007ad036c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import (\n",
    "    col, lit, when, monotonically_increasing_id, row_number,\n",
    "    year, month, dayofmonth, dayofweek, quarter, weekofyear,\n",
    "    date_format, hour, minute, second, current_date, to_date\n",
    ")\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "\n",
    "silver_table = \"oliv_mitai_uc.silver.sales_silver\"\n",
    "gold_db = \"oliv_mitai_uc.gold\"\n",
    "\n",
    "df_silver = spark.table(silver_table)\n",
    "\n",
    "# =========================================================\n",
    "# DIM_DATE\n",
    "# =========================================================\n",
    "dim_date = (\n",
    "    df_silver.select(col(\"bill_datetime\").alias(\"full_date\"))\n",
    "    .dropna()\n",
    "    .dropDuplicates()\n",
    "    .withColumn(\"date_key\", date_format(col(\"full_date\"), \"yyyyMMdd\").cast(\"int\"))\n",
    "    .withColumn(\"day_of_week\", dayofweek(col(\"full_date\")))\n",
    "    .withColumn(\"day_name\", date_format(col(\"full_date\"), \"EEEE\"))\n",
    "    .withColumn(\"day_of_month\", dayofmonth(col(\"full_date\")))\n",
    "    .withColumn(\"week_of_year\", weekofyear(col(\"full_date\")))  \n",
    "    .withColumn(\"month\", month(col(\"full_date\")))\n",
    "    .withColumn(\"month_name\", date_format(col(\"full_date\"), \"MMMM\"))\n",
    "    .withColumn(\"quarter\", quarter(col(\"full_date\")))\n",
    "    .withColumn(\"year\", year(col(\"full_date\")))\n",
    "    .withColumn(\"is_weekend\", when(col(\"day_of_week\").isin(1, 7), True).otherwise(False))\n",
    "    .withColumn(\"is_holiday\", lit(False))\n",
    ")\n",
    "\n",
    "spark.sql(f\"CREATE DATABASE IF NOT EXISTS {gold_db}\")\n",
    "\n",
    "spark.sql(f\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS {gold_db}.dim_date (\n",
    "    date_key INT,\n",
    "    full_date DATE,\n",
    "    day_of_week INT,\n",
    "    day_name STRING,\n",
    "    day_of_month INT,\n",
    "    week_of_year INT,\n",
    "    month INT,\n",
    "    month_name STRING,\n",
    "    quarter INT,\n",
    "    year INT,\n",
    "    is_weekend BOOLEAN,\n",
    "    is_holiday BOOLEAN\n",
    ")\n",
    "USING DELTA\n",
    "\"\"\")\n",
    "\n",
    "dim_date.write.option(\"overwriteSchema\", \"true\").mode(\"overwrite\").format(\"delta\").saveAsTable(f\"{gold_db}.dim_date\")\n",
    "\n",
    "# =========================================================\n",
    "# DIM_TIME\n",
    "# =========================================================\n",
    "dim_time = (\n",
    "    df_silver.select(col(\"bill_datetime\").alias(\"time_value\"))\n",
    "    .dropna()\n",
    "    .dropDuplicates()\n",
    "    .withColumn(\"hour\", hour(col(\"time_value\")))\n",
    "    .withColumn(\"minute\", minute(col(\"time_value\")))\n",
    "    .withColumn(\"second\", second(col(\"time_value\")))\n",
    "    .withColumn(\"time_key\", (col(\"hour\") * 10000 + col(\"minute\") * 100 + col(\"second\")).cast(\"int\"))\n",
    "    .withColumn(\n",
    "        \"time_bucket\",\n",
    "        when(col(\"hour\").between(6, 11), \"Morning\")\n",
    "        .when(col(\"hour\").between(12, 16), \"Afternoon\")\n",
    "        .when(col(\"hour\").between(17, 20), \"Evening\")\n",
    "        .otherwise(\"Night\")\n",
    "    )\n",
    ")\n",
    "\n",
    "spark.sql(f\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS {gold_db}.dim_time (\n",
    "    time_key INT,\n",
    "    hour INT,\n",
    "    minute INT,\n",
    "    second INT,\n",
    "    time_bucket STRING\n",
    ")\n",
    "USING DELTA\n",
    "\"\"\")\n",
    "\n",
    "dim_time.write.option(\"overwriteSchema\", \"true\").mode(\"overwrite\").format(\"delta\").saveAsTable(f\"{gold_db}.dim_time\")\n",
    "\n",
    "# =========================================================\n",
    "# DIM_STORE\n",
    "# =========================================================\n",
    "dim_store = (\n",
    "    df_silver.select(\n",
    "        \"store_code\", \"store_name\", \"address_line1\", \"city\", \"state\", \"postal_code\",\n",
    "        \"gstin\", \"phone\", \"fssai_no\", current_date().alias(\"created_date\")\n",
    "    ).dropDuplicates()\n",
    ")\n",
    "\n",
    "dim_store = dim_store.withColumn(\"store_key\", row_number().over(Window.orderBy(\"store_code\")))\n",
    "\n",
    "spark.sql(f\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS {gold_db}.dim_store (\n",
    "    store_key INT,\n",
    "    store_code STRING,\n",
    "    store_name STRING,\n",
    "    address_line1 STRING,\n",
    "    city STRING,\n",
    "    state STRING,\n",
    "    postal_code STRING,\n",
    "    gstin STRING,\n",
    "    phone STRING,\n",
    "    fssai_no STRING,\n",
    "    created_date TIMESTAMP\n",
    ")\n",
    "USING DELTA\n",
    "\"\"\")\n",
    "\n",
    "dim_store.write.option(\"overwriteSchema\", \"true\").mode(\"overwrite\").format(\"delta\").saveAsTable(f\"{gold_db}.dim_store\")\n",
    "\n",
    "# =========================================================\n",
    "# DIM_CASHIER\n",
    "# =========================================================\n",
    "dim_cashier = (\n",
    "    df_silver.select(\"cashier_code\", \"cashier_name\")\n",
    "    .dropDuplicates()\n",
    "    .withColumn(\"cashier_key\", row_number().over(Window.orderBy(\"cashier_code\")))\n",
    "    .withColumn(\"active_flag\", lit(True))\n",
    "    .withColumn(\"start_date\", lit(None).cast(\"date\"))\n",
    ")\n",
    "\n",
    "spark.sql(f\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS {gold_db}.dim_cashier (\n",
    "    cashier_key INT,\n",
    "    cashier_code STRING,\n",
    "    cashier_name STRING,\n",
    "    active_flag BOOLEAN,\n",
    "    start_date DATE\n",
    ")\n",
    "USING DELTA\n",
    "\"\"\")\n",
    "\n",
    "dim_cashier.write.option(\"overwriteSchema\", \"true\").mode(\"overwrite\").format(\"delta\").saveAsTable(f\"{gold_db}.dim_cashier\")\n",
    "\n",
    "# =========================================================\n",
    "# DIM_PRODUCT\n",
    "# =========================================================\n",
    "dim_product = (\n",
    "    df_silver.select(\"sku\", \"hsn_code\", \"product_name\", \"category\", \"uom\", \"rate\")\n",
    "    .dropDuplicates()\n",
    "    .withColumn(\"product_key\", row_number().over(Window.orderBy(\"sku\")))\n",
    "    .withColumn(\"current_price\", col(\"rate\").cast(\"decimal(12,2)\"))\n",
    "    .withColumn(\"effective_from\", lit(None).cast(\"date\"))\n",
    ")\n",
    "\n",
    "spark.sql(f\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS {gold_db}.dim_product (\n",
    "    product_key INT,\n",
    "    sku STRING,\n",
    "    hsn_code STRING,\n",
    "    product_name STRING,\n",
    "    category STRING,\n",
    "    uom STRING,\n",
    "    current_price DECIMAL(12,2),\n",
    "    effective_from DATE\n",
    ")\n",
    "USING DELTA\n",
    "\"\"\")\n",
    "\n",
    "dim_product.write.option(\"overwriteSchema\", \"true\").mode(\"overwrite\").format(\"delta\").saveAsTable(f\"{gold_db}.dim_product\")\n",
    "\n",
    "# =========================================================\n",
    "# DIM_PAYMENT_METHOD\n",
    "# =========================================================\n",
    "dim_payment = (\n",
    "    df_silver.select(\"payment_method\")\n",
    "    .dropDuplicates()\n",
    "    .withColumn(\"payment_method_key\", row_number().over(Window.orderBy(\"payment_method\")))\n",
    "    .withColumn(\"method_code\", col(\"payment_method\"))\n",
    "    .withColumn(\"method_name\", col(\"payment_method\"))\n",
    ")\n",
    "\n",
    "spark.sql(f\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS {gold_db}.dim_payment_method (\n",
    "    payment_method_key INT,\n",
    "    method_code STRING,\n",
    "    method_name STRING\n",
    ")\n",
    "USING DELTA\n",
    "\"\"\")\n",
    "\n",
    "dim_payment.write.option(\"overwriteSchema\", \"true\").mode(\"overwrite\").format(\"delta\").saveAsTable(f\"{gold_db}.dim_payment_method\")\n",
    "\n",
    "# =========================================================\n",
    "# DIM_RECEIPT\n",
    "# =========================================================\n",
    "dim_receipt = (\n",
    "    df_silver.select(\n",
    "        \"bill_no\", \"bill_datetime\", \"store_code\", \"cashier_code\",\n",
    "        \"counter_name\", \"payment_method\", \"total_amount\"\n",
    "    )\n",
    "    .dropDuplicates()\n",
    "    .withColumn(\"receipt_key\", row_number().over(Window.orderBy(\"bill_no\")))\n",
    ")\n",
    "\n",
    "spark.sql(f\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS {gold_db}.dim_receipt (\n",
    "    receipt_key INT,\n",
    "    store_key INT,\n",
    "    bill_no STRING,\n",
    "    bill_datetime TIMESTAMP,\n",
    "    customer_id INT,\n",
    "    cashier_key INT,\n",
    "    counter_key INT,\n",
    "    payment_method_key INT,\n",
    "    total_amount DECIMAL(12,2)\n",
    ")\n",
    "USING DELTA\n",
    "\"\"\")\n",
    "\n",
    "dim_receipt.write.option(\"overwriteSchema\", \"true\").mode(\"overwrite\").format(\"delta\").saveAsTable(f\"{gold_db}.dim_receipt\")\n",
    "\n",
    "# =========================================================\n",
    "# FACT_SALES_LINE\n",
    "# =========================================================\n",
    "\n",
    "fact_sales = (\n",
    "    df_silver.select(\n",
    "        \"bill_no\",\n",
    "        \"bill_datetime\",\n",
    "        \"store_code\",\n",
    "        \"cashier_code\",\n",
    "        \"counter_name\",\n",
    "        \"sku\",\n",
    "        \"product_name\",\n",
    "        \"category\",\n",
    "        \"uom\",\n",
    "        \"tax_percent\",\n",
    "        \"tax_amount\",\n",
    "        \"quantity\",\n",
    "        \"rate\",\n",
    "        \"amount\",\n",
    "        \"payment_method\",\n",
    "        \"total_amount\"\n",
    "    )\n",
    "    .withColumn(\"bill_date\", to_date(col(\"bill_datetime\")))\n",
    "    .withColumn(\"bill_time\", date_format(col(\"bill_datetime\"), \"HH:mm:ss\"))\n",
    "    .withColumn(\"unit_rate\", col(\"rate\"))\n",
    "    .withColumn(\"line_amount_excl_tax\", col(\"amount\"))\n",
    "    .withColumn(\"line_amount_incl_tax\", col(\"amount\") + col(\"tax_amount\"))\n",
    "    .withColumn(\"load_datetime\", col(\"bill_datetime\"))\n",
    "    .withColumn(\"fact_line_key\", monotonically_increasing_id())\n",
    "    .withColumn(\"source_bill_no\", col(\"bill_no\"))\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "fact_sales.write.option(\"overwriteSchema\", \"true\").mode(\"overwrite\").format(\"delta\").saveAsTable(f\"{gold_db}.fact_sales_line\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bb817b3e-b5d4-4f2e-aa60-7f5794022de2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "select * from oliv_mitai_uc.gold.fact_sales_line"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 5311862321626837,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "silver_To_gold_etl",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
